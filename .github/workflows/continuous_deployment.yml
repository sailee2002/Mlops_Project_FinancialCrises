name: Continuous Deployment

on:
  push:
    branches:
      - main
    paths:
      - "src/**"
      - "tests/**"
  workflow_dispatch:

env:
  PYTHON_VERSION: "3.10"
  GCP_BUCKET: "mlops-financial-stress-data"

jobs:
  run-tests:
    runs-on: ubuntu-latest
    
    steps:
      - uses: actions/checkout@v4
      
      - uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Free disk space
        run: |
          sudo rm -rf /usr/share/dotnet
          sudo rm -rf /usr/local/lib/android
          sudo rm -rf /opt/ghc

      - name: Install dependencies
        run: |
          pip install --upgrade pip
          pip install -r requirements.txt
          pip install pytest
      
      - name: Run tests
        run: |
          if [ -d "tests" ]; then
            pytest tests/ || echo "No tests found or tests failed"
          else
            echo "No tests directory found - skipping"
          fi
        continue-on-error: true

  # NEW JOB: Download and prepare data from GCP
  prepare-data:
    runs-on: ubuntu-latest
    needs: [run-tests]
    
    steps:
      - uses: actions/checkout@v4
      
      - uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      
      # Authenticate with GCP
      - name: Authenticate to Google Cloud
        uses: google-github-actions/auth@v2
        with:
          credentials_json: ${{ secrets.GCP_SA_KEY }}
      
      - name: Set up Cloud SDK
        uses: google-github-actions/setup-gcloud@v2
      
      - name: Free disk space
        run: |
          sudo rm -rf /usr/share/dotnet
          sudo rm -rf /usr/local/lib/android
          sudo rm -rf /opt/ghc

      - name: Install dependencies
        run: |
          pip install --upgrade pip
          pip install -r requirements.txt
      
      # Download data from GCP
      - name: Download data from GCS
        run: |
          echo "üì• Downloading data from GCS..."
          mkdir -p data/processed data/features data/splits
          
          # Download the features_engineered.csv
          gsutil cp gs://${{ env.GCP_BUCKET }}/data/processed/features_engineered.csv data/processed/ || echo "File not found"
          
          # Try to download pre-existing splits (if they exist)
          gsutil -m cp gs://${{ env.GCP_BUCKET }}/data/splits/*.csv data/splits/ || echo "Splits not found, will generate"
          
          echo "‚úÖ Download complete"
      
      - name: Check what data we have
        run: |
          echo "Checking data files..."
          if [ -f "data/processed/features_engineered.csv" ]; then
            echo "‚úÖ features_engineered.csv found"
            ls -lh data/processed/features_engineered.csv
          fi
          
          if [ -f "data/splits/train_data.csv" ]; then
            echo "‚úÖ Splits already exist in GCS"
            ls -lh data/splits/
          else
            echo "‚ö†Ô∏è  Splits not found, need to generate"
          fi
      
      - name: Generate data splits (if needed)
        run: |
          if [ ! -f "data/splits/train_data.csv" ]; then
            echo "üìä Generating data splits..."
            
            # Step 1: Create targets
            python src/models/create_target.py

            # Step 2: Drop unused columns
            python src/preprocessing/drop_features.py

            # Step 3: Create temporal splits
            python src/preprocessing/temporal_split.py
            
            # Step 4: Handle outliers
            python src/preprocessing/handle_outliers_after_split.py
            
            echo "‚úÖ Splits generated"
            
            # Upload splits back to GCS
            echo "üì§ Uploading splits to GCS..."
            gsutil -m cp data/splits/*.csv gs://${{ env.GCP_BUCKET }}/data/splits/
            gsutil cp data/features/quarterly_data_with_targets.csv gs://${{ env.GCP_BUCKET }}/data/features/
            echo "‚úÖ Uploaded to GCS"
          fi
        continue-on-error: true
      
      - name: Upload data splits as artifact
        uses: actions/upload-artifact@v4
        with:
          name: data-splits
          path: |
            data/splits/train_data.csv
            data/splits/val_data.csv
            data/splits/test_data.csv
          retention-days: 7
        continue-on-error: true

  # MODIFIED JOB: Train model using downloaded data
  train-model:
    runs-on: ubuntu-latest
    needs: [run-tests, prepare-data]
    
    steps:
      - uses: actions/checkout@v4
      
      - uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      
      - name: Free disk space
        run: |
          sudo rm -rf /usr/share/dotnet
          sudo rm -rf /usr/local/lib/android
          sudo rm -rf /opt/ghc
          
      - name: Install dependencies
        run: |
          pip install --upgrade pip
          pip install -r requirements.txt
      
      # Download the artifact from previous job
      - name: Download data splits
        uses: actions/download-artifact@v4
        with:
          name: data-splits
          path: data/splits
      
      - name: Verify data exists
        id: check_data
        run: |
          if [ -f "data/splits/train_data.csv" ]; then
            echo "data_exists=true" >> $GITHUB_OUTPUT
            echo "‚úÖ Data splits found"
            ls -lh data/splits/
          else
            echo "data_exists=false" >> $GITHUB_OUTPUT
            echo "‚ö†Ô∏è  Data splits not found"
          fi
      
      - name: Train XGBoost (revenue only)
        if: steps.check_data.outputs.data_exists == 'true'
        run: |
          python src/models/xgboost_model.py \
            --target revenue \
            --splits-dir data/splits \
            --output-dir models/xgboost \
            --no-mlflow
        continue-on-error: true
      
      - name: Check training results
        if: steps.check_data.outputs.data_exists == 'true'
        run: |
          if [ -f "models/xgboost/xgboost_revenue_metrics.json" ]; then
            echo "‚úÖ Model trained successfully!"
            echo ""
            echo "Model Metrics:"
            cat models/xgboost/xgboost_revenue_metrics.json
          else
            echo "‚ö†Ô∏è  Model training may have failed"
          fi
        continue-on-error: true
      
      # Upload trained model back to GCS
      - name: Upload model to GCS
        if: steps.check_data.outputs.data_exists == 'true'
        uses: google-github-actions/auth@v2
        with:
          credentials_json: ${{ secrets.GCP_SA_KEY }}
      
      - name: Upload model files to GCS
        if: steps.check_data.outputs.data_exists == 'true'
        run: |
          gcloud config set project ninth-iris-422916-f2
          gsutil -m cp models/xgboost/* gs://${{ env.GCP_BUCKET }}/models/xgboost/
          echo "‚úÖ Model uploaded to GCS"
        continue-on-error: true
      
      - name: Upload trained model as artifact
        if: steps.check_data.outputs.data_exists == 'true'
        uses: actions/upload-artifact@v4
        with:
          name: xgboost-revenue-model
          path: |
            models/xgboost/xgboost_revenue.pkl
            models/xgboost/xgboost_revenue_metrics.json
            models/xgboost/xgboost_revenue_importance.csv
          retention-days: 30
        continue-on-error: true

  pipeline-summary:
    runs-on: ubuntu-latest
    needs: [run-tests, prepare-data, train-model]
    if: always()
    
    steps:
      - name: Display summary
        run: |
          echo "=================================="
          echo "SIMPLE CI/CD PIPELINE SUMMARY"
          echo "=================================="
          echo ""
          echo "Tests: ${{ needs.run-tests.result }}"
          echo "Data Preparation: ${{ needs.prepare-data.result }}"
          echo "Model Training: ${{ needs.train-model.result }}"
          echo ""
          if [ "${{ needs.train-model.result }}" == "success" ]; then
            echo "‚úÖ Pipeline completed successfully!"
            echo ""
            echo "Model and data stored in GCS bucket: mlops-financial-stress-data"
          else
            echo "‚ö†Ô∏è  Check logs for details"
          fi